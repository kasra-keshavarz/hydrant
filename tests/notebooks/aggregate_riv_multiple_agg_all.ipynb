{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "153ef8ff-3db8-4fd0-922b-6125c862426a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "from dask.distributed import (\n",
    "    Client,\n",
    ")\n",
    "\n",
    "from shapely.geometry import (\n",
    "    LineString,\n",
    "    Point,\n",
    ")\n",
    "\n",
    "from shapely import (\n",
    "    union_all,\n",
    "    ops,\n",
    ")\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "from typing import (\n",
    "    Dict,\n",
    "    TypeAlias,\n",
    "    Any,\n",
    "    Optional,\n",
    ")\n",
    "\n",
    "from collections.abc import (\n",
    "    Collection,\n",
    "    Callable,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36698100-e0f3-4d5d-b575-414ed25bc060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MERIT-Basins path\n",
    "mb_path = '/project/rrg-mclark/data/geospatial-data/MERIT-Basins/MERIT_Hydro_v07_Basins_v01_bugfix1/'\n",
    "\n",
    "# cat layer\n",
    "cat = gpd.read_file(os.path.join(mb_path, 'pfaf_level_02', 'cat_pfaf_72_MERIT_Hydro_v07_Basins_v01_bugfix1.shp'))\n",
    "\n",
    "# riv layer\n",
    "riv = gpd.read_file(os.path.join(mb_path, 'pfaf_level_02', 'riv_pfaf_72_MERIT_Hydro_v07_Basins_v01_bugfix1.shp'))\n",
    "\n",
    "# cst layer\n",
    "cst = gpd.read_file(os.path.join(mb_path, 'coastal_hillslopes', 'hillslope_72_clean.shp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "090f19b6-6cf2-4fc7-904d-a5bab8105524",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _aggregate_attr(\n",
    "    rg: nx.DiGraph,\n",
    "    successor: str | float | int,\n",
    "    predecessor: float | int | Collection[float | int],\n",
    "    attr: str,\n",
    "    method: str | Callable,\n",
    "    *args: Any,\n",
    "    **kwargs: Dict[Any, Any],\n",
    ") -> float | int:\n",
    "    \"\"\"Aggregate `attr` values given a `method` of choice that is either\n",
    "    one of the pre-defined aggregation methods, or a user-defined\n",
    "    function. If the user-defined function accepts more arguments, they\n",
    "    can be fed using `args` or `kwargs`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rg : ``networkx.DiGraph``\n",
    "        A directed acyclic graph of a river network of interest, where\n",
    "        each node (river confluence) has the same attribute of its outgoing\n",
    "        edge (river).\n",
    "    successor : str, float, or int depending on `rg`'s nodes datatypes\n",
    "        `rg`'s node (river confluence) or its corresponding outgoing edge\n",
    "        (river segment) which is going to be aggregated and further\n",
    "        contracted with one or all of its predecessors. Node contraction\n",
    "        is not done in this method.\n",
    "    predecessor : str, float, or int depending on `rg`'s nodes datatypes\n",
    "        `rg`'s node (river confluence) or its corresponding outgoing edge\n",
    "        (river segment) which is going to be aggregated and further\n",
    "        contracted with its successor. Node contraction is not done in\n",
    "        this method.\n",
    "    attr : str\n",
    "        Target attribute for aggregation\n",
    "    method : str or a user-defined function\n",
    "        Method for aggregation of `attr` values of `successor` and\n",
    "        `predecessor` nodes. It can be one of the pre-defined methods\n",
    "        or a user-defined function; in case of a user-defined function,\n",
    "        if necessary, extra arguments to the `method` function can be\n",
    "        provided using `*args` or `**kwargs`. A single dictionary of\n",
    "        all elements of `successor` and `predecessor` is passed to the\n",
    "        used-defined function.  \n",
    "        Current pre-defined methods are: 'sum', 'mean', 'min', 'max',\n",
    "        'upstream', and 'downstream'.\n",
    "    \n",
    "    Other Parameters\n",
    "    ----------------\n",
    "    agrs: ``any``\n",
    "        The arguments to be fed to `method`, if a user-defined function\n",
    "        is provided. Raises ``ValueError`` exception if method is not\n",
    "        callable.\n",
    "    kwargs: dict\n",
    "        The keys of this `dict` are the input arguments to `method`\n",
    "        if a user-defined function is given; the values must follow the\n",
    "        datatype of `method`'s arguments'.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        The keys are each of the `predecessor` and values are the\n",
    "        aggregated `attr` given `sucessor` and `predecessor` values\n",
    "        based on the user's `method`\n",
    "    \n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If `args` and/or `kwargs` are provided while `method` is not a\n",
    "        user-defined function.\n",
    "    TypeError\n",
    "        If the content of `attr` is not ``float`` or ``int``, then an\n",
    "        ``TypeError`` is raised\n",
    "    \"\"\"\n",
    "    # if args or kwargs are provided and `method` is not a user-defined\n",
    "    # function, raise a ValueError exception\n",
    "    if isinstance(method, str):\n",
    "        if bool(args) or bool(kwargs):\n",
    "            raise ValueError(\"arguments provided through `args` or `kwargs`\"\n",
    "                             \" while `method` is not a user-defined\"\n",
    "                             \" function\")\n",
    "    # check the data type of `attr`\n",
    "    if not isinstance(attr, (str, int, float)):\n",
    "        raise TypeError(\"`attr` must be of type str, int, or float\")\n",
    "        \n",
    "    # build attribute dictionary\n",
    "    attr_dict = nx.get_node_attributes(\n",
    "        G=rg,\n",
    "        name=attr,\n",
    "    )\n",
    "    \n",
    "    # build a dictionaries of elements to be aggregated\n",
    "    successor_dict = {'successor': rg.nodes[successor][attr]}\n",
    "    predecessor_dict = {'predecessor': rg.nodes[predecessor][attr]}\n",
    "    \n",
    "    # create a list of both dictionaries for easier access\n",
    "    node_dict = {**successor_dict, **predecessor_dict}\n",
    "    \n",
    "    # dict value iterator in case all values are needed in one go\n",
    "    all_attr_values = node_dict.values()\n",
    "    \n",
    "    # checking `method`\n",
    "    # simple summation\n",
    "    if callable(method):\n",
    "        return method(**node_dict, **kwargs)\n",
    "    elif method in ('sum'):\n",
    "        return sum(all_attr_values)\n",
    "    # simple average\n",
    "    elif method in ('mean'):\n",
    "        return sum(all_attr_values) / len(all_attr_values)\n",
    "    # minimum value\n",
    "    elif method in ('min'):\n",
    "        return min(all_attr_values)\n",
    "    # maximum value\n",
    "    elif method in ('max'):\n",
    "        return max(all_attr_values)\n",
    "    # get the upstream value given a target upstream\n",
    "    elif method in ('upstream'):\n",
    "        return ht.agg_funcs.upstream(\n",
    "            successor,\n",
    "            predecessor,\n",
    "            *args,\n",
    "            **kwargs,\n",
    "        )\n",
    "    # get the downstream value\n",
    "    elif method in ('downstream'):\n",
    "        return ht.agg_funcs.downstream(\n",
    "            successor,\n",
    "            predecessor,\n",
    "            *args,\n",
    "            **kwargs,\n",
    "        )\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfa37f76-cd26-497e-a5de-d126e514c389",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _aggregate_linestring_geoms(\n",
    "    successor: LineString,\n",
    "    predecessor: LineString,\n",
    ") -> LineString:\n",
    "    \"\"\"Aggregated (Multi-)LineString geometries for `successor` and\n",
    "    `predecessor` objects\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    successor: shapely.geometry.LineString\n",
    "        sucessor LineString to be aggregated\n",
    "    predecessor: shapely.geometry.LineString\n",
    "        predecessor LineString to be aggregated with `successor`\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    shapely.LineString:\n",
    "        aggregated LineString geometry\n",
    "    \"\"\"\n",
    "    # check if successor and predecessor are shapely.geometry.LineString types\n",
    "    if not isinstance(successor, LineString):\n",
    "        raise TypeError(\"`successor` must be of type shapely.geometry.LineString\")\n",
    "    if not isinstance(predecessor, LineString):\n",
    "        raise TypeError(\"`predecessor` must be of type shapely.geometry.LineString\")\n",
    "        \n",
    "    return ops.linemerge(union_all([successor, predecessor]))\n",
    "\n",
    "def linestrings_endpoint_distance(\n",
    "    successor: LineString,\n",
    "    predecessor: LineString,\n",
    "    linestring_epsg: Optional[int] = 4326,\n",
    "    distance_epsg: Optional[int] = 6933,\n",
    "    *args,\n",
    "    **kwargs,\n",
    ") -> float:\n",
    "    \"\"\"Calculate the horizontal direct distance between the end points of\n",
    "    two connected shapely.LineString objects. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    successor : shapely.LineString\n",
    "        The successer river segment that shares a point(s) with the\n",
    "        `predecessor` object.\n",
    "    predecessor : shapely.LineString\n",
    "        The predecessor to `successor` object shareing a common point(s).\n",
    "    linestring_epsg : int, optional [defaults to `4326`]\n",
    "        the source EPSG code describing the `crs` of both the `successor` and\n",
    "        `predecessor` objects. Either `epsg` or `crs` options could be used\n",
    "        but not both.\n",
    "    distance_epsg : int, optional [defailts to `6933`]\n",
    "        the target EPSG code used to calculate the distance between the\n",
    "        coordinates.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The horizontal distance between the endpoints of two given\n",
    "        shapely.LineString objects. The unit of the returned value is in\n",
    "        `meters`, if the `distance_epsg` is set to its default value of\n",
    "        `6933`.\n",
    "    \n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If `successor` and `predecessor` do not share a common point(s), this\n",
    "        exception will be raised.\n",
    "    \"\"\"\n",
    "    # check the dtype of `successor` and `predecessor`\n",
    "    for v in [successor, predecessor]:\n",
    "        if not isinstance(v, LineString):\n",
    "            raise ValueError(\"Two given LineStrings do not touch\")\n",
    "\n",
    "    # check if there is a common point (coordinate) shared between\n",
    "    # `successor` and `predecessor`\n",
    "    shared_point = set(successor.coords).intersection(set(predecessor.coords))\n",
    "    if not shared_point:\n",
    "        raise ValueError(\"A common point shared between LineString \"\n",
    "                         \"objects is missing\")\n",
    "\n",
    "    # aggregate the geometries of LineString objects\n",
    "    agg_line = _aggregate_linestring_geoms(successor, predecessor)\n",
    "\n",
    "    # extract the end points\n",
    "    end_points = (\n",
    "        Point(agg_line.coords[0]), \n",
    "        Point(agg_line.coords[-1])\n",
    "    )\n",
    "\n",
    "    # transform the given `linestring_EPSG` to an equal area \n",
    "    # `distance_epsg`\n",
    "    transformer = Transformer.from_crs(\n",
    "        linestring_epsg,\n",
    "        distance_epsg,\n",
    "        always_xy=True,\n",
    "    )\n",
    "    \n",
    "    # equal-area projection transformed end_points\n",
    "    transformed_end_points = \\\n",
    "        [Point(transformer.transform(geom.x, geom.y))\n",
    "             for geom in end_points]\n",
    "\n",
    "    # calculate distance\n",
    "    # return end_points\n",
    "    return _coords_spatial_distance(\n",
    "        transformed_end_points[0],\n",
    "        transformed_end_points[1],\n",
    "    )\n",
    "\n",
    "def _coords_spatial_distance(\n",
    "    p1: Point,\n",
    "    p2: Point,\n",
    ") -> float:\n",
    "    \"\"\"Return the distance between `p1` and `p2`\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    p1 : shapely.Point\n",
    "        Coordinates of the first point\n",
    "    p2 : shapely.Point\n",
    "        Coordinates of the second point\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The distance (2D or 3D, depending on Point data) between `p1` and `p2`\n",
    "    \"\"\"\n",
    "\n",
    "    return p1.distance(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc392695-56a5-40a0-81d5-5113e18acd04",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def upstream_attr(\n",
    "    successor: Any,\n",
    "    predecessor: Any,\n",
    "    *args,\n",
    "    **kwargs,\n",
    ") -> Any:\n",
    "    \"\"\"Return the predecessor's attribute\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    successor : Any\n",
    "        successor attribute value to be ignored\n",
    "    predecessor : Any\n",
    "        predecessor attribute value to be returned\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    predecessor : Any\n",
    "        attribute value to be returned\n",
    "    \"\"\"\n",
    "    if not predecessor:\n",
    "        warnings.warn(f\"`predecessor` is set to {predecessor}\")\n",
    "    \n",
    "    return predecessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9460f40-9928-4776-b664-5f1c7404ab9f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def downstream_attr(\n",
    "    successor: Any,\n",
    "    predecessor: Any = None,\n",
    "    *args,\n",
    "    **kwargs,\n",
    ") -> Any:\n",
    "    \"\"\"Return the predecessor's attribute\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    successor : Any\n",
    "        successor attribute value to be returned\n",
    "    predecessor : Any\n",
    "        predecessor attribute value to be ignored\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    successor : Any\n",
    "        attribute value to be returned\n",
    "    \"\"\"\n",
    "    if successor is None:\n",
    "        warnings.warn(\"`successor` is set to None\")\n",
    "    \n",
    "    return successor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9663d65-2c12-496b-88a7-44ff7e2a0d28",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def weighted_mean(\n",
    "    succesor: Any,\n",
    "    predecessor: Any,\n",
    "    successor_weight: float,\n",
    "    predecessor_weight: float,\n",
    "    *args,\n",
    "    **kwargs,\n",
    ") -> Any:\n",
    "    \"\"\"Weighted average of `successor` and `predecessor` values given the\n",
    "    `successor_weight` and `predecessor_weight` weights\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    successor : Any\n",
    "        successor segment attribute value\n",
    "    predecessor : Any\n",
    "        predecessor segment attribute value\n",
    "    successor_weight : float\n",
    "        weight for the `successor`\n",
    "    predecessor_weight : float\n",
    "        weight for the `predecessor`\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float | int\n",
    "        weighted mean of input arguments\n",
    "    \"\"\"\n",
    "    numerator = (succesor * successor_weight) + (predecessor * predecessor_weight)\n",
    "    denominator = (successor_weight + predecessor_weight)\n",
    "    \n",
    "    return numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7601647-d4d4-4b4e-9e03-3cd665b96523",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def is_int(s):\n",
    "    try: \n",
    "        int(s)\n",
    "    except ValueError:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3629375d-796f-44ad-bf34-b8dcbcd7b26c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def spatial_linestring_agg(\n",
    "    successor: LineString,\n",
    "    predecessor: LineString,\n",
    ") -> LineString:\n",
    "    \"\"\"Aggregated (Multi-)LineString geometries for `successor` and\n",
    "    `predecessor` objects\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    successor: shapely.geometry.LineString\n",
    "        sucessor LineString to be aggregated\n",
    "    predecessor: shapely.geometry.LineString\n",
    "        predecessor LineString to be aggregated with `successor`\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    shapely.LineString:\n",
    "        aggregated LineString geometry\n",
    "    \"\"\"\n",
    "    # check if successor and predecessor are shapely.geometry.LineString types\n",
    "    if not isinstance(successor, LineString):\n",
    "        raise TypeError(\"`successor` must be of type shapely.geometry.LineString\")\n",
    "    if not isinstance(predecessor, LineString):\n",
    "        raise TypeError(\"`predecessor` must be of type shapely.geometry.LineString\")\n",
    "        \n",
    "    return ops.linemerge(union_all([successor, predecessor]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7bdbac9-e94c-4c34-b236-3c452c1ab8f5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "NodeType: TypeAlias = str | int\n",
    "AttrType: TypeAlias = str\n",
    "\n",
    "def _aggregate_single_seg(\n",
    "    rg: nx.DiGraph,\n",
    "    successor: NodeType,\n",
    "    predecessor: NodeType,\n",
    "    attrs: Collection[AttrType] = None,\n",
    "    attr_agg_funcs: Dict[AttrType, Callable] = None,\n",
    "    attr_agg_funcs_args : Dict[Callable, Dict[str, Any]] = None,\n",
    "    inplace = True,\n",
    "    *args,\n",
    "    **kwargs,\n",
    ") -> None:\n",
    "    \"\"\"Aggregation of a chosen river segment with an upstream segment.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rg : networkx.DiGraph\n",
    "        A river network in form of a directed acyclic graph (DAG) representing\n",
    "        connections of river segments. Each graph \"vertex\" (or \"node\")\n",
    "        represents its downstream river segments that is depicted as an \"arc\".\n",
    "    successor : str or int, or a collection of the previous data types\n",
    "        River segment or list of segments to be contracted. In ``hydrant``, a\n",
    "        river segment is always aggregated with its upstream ones. In case of\n",
    "        a list of segments, all predecessors (i.e., upstream) segments will be\n",
    "        used.\n",
    "    predecessor : str or int, or a collection of the previous data types\n",
    "        Upstream river segment to be aggregated with the `successor`.\n",
    "    attrs : list-like object of str, optional\n",
    "        The attributes to be included in the aggregation process.\n",
    "    attr_agg_funcs : Callable, optional\n",
    "        Functions to be applied to the `attrs` elements. If extra arguments\n",
    "        needed, `agg_funcs_args` dictionary could be used.\n",
    "    attr_agg_funcs_args : Callable, optional\n",
    "        Extra arguments to be fed to each of the `attr_agg_funcs` functions\n",
    "        with keys corresponding to any `attrs_agg_funcs` elements that needs\n",
    "        extra options.\n",
    "    inplace : bool, optional [defaults to True]\n",
    "        If operation is done inplace, nothing is returned, else, the copy of \n",
    "        the network including aggregation changes are returned.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    networkx.DiGraph\n",
    "        DAG with `successors` aggregated with its predecessors (upstream\n",
    "        segments)\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    The following, creates a sample river network and aggregated the shortest\n",
    "    river segment with all its upstream reaches\n",
    "    >>> rg = \n",
    "    \n",
    "    \"\"\"\n",
    "    # If operations need to be done \"inplace\", do not make a copy\n",
    "    if inplace:\n",
    "        pass\n",
    "    else:\n",
    "        rg = rg.copy()\n",
    "    \n",
    "    # FIXME: This should not be different from other attributes\n",
    "    if 'geometry' in attrs:\n",
    "        # do geometrical aggregation\n",
    "        val = attr_agg_funcs['geometry'](\n",
    "            successor=rg.nodes[successor]['geometry'],\n",
    "            predecessor=rg.nodes[predecessor]['geometry'],\n",
    "        )\n",
    "        nx.set_node_attributes(rg, {predecessor: val}, name='geometry')\n",
    "    \n",
    "    # aggregate attributes\n",
    "    for attr in attrs:\n",
    "        # FIXME: temporary measure\n",
    "        if attr == 'geometry':\n",
    "            continue\n",
    "        # check if aditional arguments should be provided to the \n",
    "        # aggregation function\n",
    "        if attr in attr_agg_funcs_args:\n",
    "            args = attr_agg_funcs_args[attr]\n",
    "        else:\n",
    "            args = {}\n",
    "            \n",
    "        val = _aggregate_attr(\n",
    "            rg=rg,\n",
    "            successor=successor,\n",
    "            predecessor=predecessor,\n",
    "            attr=attr,\n",
    "            method=attr_agg_funcs[attr],\n",
    "            **args\n",
    "        )\n",
    "        nx.set_node_attributes(rg, {predecessor: val}, name=attr)\n",
    "    \n",
    "    if inplace:\n",
    "        return\n",
    "    else:\n",
    "        return rg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "743ff665-efbd-485d-b257-51fe6bfe5bcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # define the river network\n",
    "# rg = nx.from_pandas_edgelist(\n",
    "#     df=riv,\n",
    "#     source='COMID',\n",
    "#     target='NextDownID',\n",
    "#     edge_attr=riv.columns.to_list(),\n",
    "#     create_using=nx.DiGraph\n",
    "# )\n",
    "# # each river confluence (networkx node) corresponds to its outgoing edge\n",
    "# # (river segment), and all attributes are similar for both objects\n",
    "# nx.set_node_attributes(\n",
    "#     G=rg,\n",
    "#     values=riv.set_index('COMID', drop=False).T.to_dict()\n",
    "# )\n",
    "\n",
    "# # successor\n",
    "# successor = 72051873\n",
    "# # predecessor\n",
    "# predecessor = 72053625\n",
    "\n",
    "# # attribute list\n",
    "# attrs = [\n",
    "#     'lengthkm',\n",
    "#     'uparea',\n",
    "#     'order',\n",
    "#     'geometry',\n",
    "# ]\n",
    "\n",
    "# # aggregation functions for each attribute element\n",
    "# attr_agg_funcs = {\n",
    "#     'lengthkm': 'sum',\n",
    "#     'uparea': 'sum',\n",
    "#     'order': upstream_attr,\n",
    "#     'geometry': spatial_linestring_agg,\n",
    "# }\n",
    "\n",
    "# # aggregation functions' extra arguments\n",
    "# attr_agg_funcs_args = {\n",
    "# }\n",
    "\n",
    "\n",
    "# new_rg = _aggregate_single_seg(\n",
    "#     rg=rg,\n",
    "#     successor=successor,\n",
    "#     predecessor=predecessor,\n",
    "#     attrs=attrs,\n",
    "#     attr_agg_funcs=attr_agg_funcs,\n",
    "#     attr_agg_funcs_args=attr_agg_funcs_args,\n",
    "#     inplace=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47887f03-6ebb-4785-864e-13cc3fbef8e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# gpd.GeoDataFrame(geometry=[new_rg.nodes[72053625]['geometry']]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d8539c2-0019-424c-9b4c-5eec54ff701c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# gpd.GeoDataFrame(geometry=[rg.nodes[72053625]['geometry']]).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c683ee90-69c9-4afe-be0c-89ce0ddf7722",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11729bb-9ef5-4528-84c1-bf2958d5aa59",
   "metadata": {},
   "source": [
    "We would like to generalize the appraoch, and only provide a list of nodes that we would like to aggregate with all its upstream segments and finally contract it from the river network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7f58009-716e-491f-9b73-5b6807568100",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the river network\n",
    "rg = nx.from_pandas_edgelist(\n",
    "    df=riv,\n",
    "    source='COMID',\n",
    "    target='NextDownID',\n",
    "    create_using=nx.DiGraph\n",
    ")\n",
    "# each river confluence (networkx node) corresponds to its outgoing edge\n",
    "# (river segment), and all attributes are similar for both objects\n",
    "nx.set_node_attributes(\n",
    "    G=rg,\n",
    "    values=riv.set_index('COMID', drop=False).T.to_dict()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86a80cb5-055b-4130-89a2-0becec0ae7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_segments(\n",
    "    rg: nx.DiGraph,\n",
    "    segments: Collection[NodeType],\n",
    "    main_id = None,\n",
    "    ds_main_id = None,\n",
    "    attrs: Collection[str] = [],\n",
    "    agg_funcs: Dict[str, str | Callable] = {},\n",
    "    agg_funcs_kwargs: Dict[str, Dict[str, Any]] = {},\n",
    "    contraction: bool = True,\n",
    "    dask_client: Client = None,\n",
    "    *args,\n",
    "    **kwargs\n",
    ") -> nx.DiGraph:\n",
    "    \"\"\"Aggregate selected river segments in a directed acyclic graph of a river\n",
    "    network.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rg : networkx.DiGraph\n",
    "        A river network in form of a directed acyclic graph (DAG) representing\n",
    "        connections of river segments. Each graph \"vertex\" (or \"node\")\n",
    "        represents its downstream river segments that is depicted as an \"arc\"\n",
    "        (or \"edge\"). The attribute table of each \"node\" is similar to its\n",
    "        outgoing (or downstream) \"arc\" (or \"edge\").\n",
    "    segments : List-like object of str or int\n",
    "        List-like collection of segments to be aggregated with their upstream\n",
    "        segments. In ``hydrant``, a river segment is always aggregated with its\n",
    "        upstream ones. In case of a list of segments, all predecessors\n",
    "        (i.e., upstream) segments will be used.\n",
    "    attrs : list-like object of str, optional\n",
    "        The attributes to be included in the aggregation process.\n",
    "    agg_funcs : dict, optional\n",
    "        Functions to be applied to the `attrs` elements. If extra arguments\n",
    "        needed, `agg_funcs_kwargs` dictionary could be used. The keys of this\n",
    "        dictionary are all elements of `attrs`, and the values can be either\n",
    "        the pre-defined functions (str value), or Callable functions. Callables\n",
    "        need to accept at least two arguments, namely `successor` and\n",
    "        `predecessor`.\n",
    "    agg_funcs_kwargs : dict, optional\n",
    "        Extra arguments to be fed to each of the `agg_funcs` functions\n",
    "        with keys corresponding to any `agg_funcs` elements. The values are\n",
    "        dictionaries that will be broadcasted while fed to the functions.\n",
    "    contraction : bool, optional [defaults to True]\n",
    "        By default, the method removes the river segment from the network and\n",
    "        assures the connectivity of upstream/downstream is valid after each \n",
    "        element of `node` is removed\n",
    "    dask_client : dask.Client\n",
    "        Dask client to be used for parallel processing of geofabrics, currently\n",
    "        not implemented yet.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    networkx.DiGraph\n",
    "        A corrected (aggregated) DiGraph of the given river network\n",
    "        \n",
    "    Raises\n",
    "    ------\n",
    "    NotImplementedError:\n",
    "        When a dask.Client is provided to `dask_client` option. This is a work\n",
    "        in progress and parallel adjustments of geospatial fabric is not\n",
    "        implemented yet in ``hydrant``.\n",
    "    \n",
    "    \"\"\"\n",
    "    # extract all the upstream (predecessor) segments of each `node`\n",
    "    predecessors = {node: list(rg.predecessors(node)) for node in segments}\n",
    "    \n",
    "    # serial processing\n",
    "    if dask_client is None:\n",
    "        # start with each node\n",
    "        for node in segments:\n",
    "            # extract all predecessors and loop through\n",
    "            for predecessor in predecessors[node]:\n",
    "                # aggregate attributes, including 'geometry' if given\n",
    "                _aggregate_single_seg(\n",
    "                    rg=rg,\n",
    "                    successor=node,\n",
    "                    predecessor=predecessor,\n",
    "                    attrs=attrs,\n",
    "                    attr_agg_funcs=agg_funcs,\n",
    "                    attr_agg_funcs_args=agg_funcs_kwargs,\n",
    "                    inplace=True,\n",
    "                )\n",
    "                # change network connectivity\n",
    "                if contraction:\n",
    "                    # node atttribute modification\n",
    "                    nx.set_node_attributes(\n",
    "                        rg,\n",
    "                        {\n",
    "                            predecessor: {\n",
    "                                ds_main_id: rg.nodes[node][ds_main_id]\n",
    "                            },\n",
    "                        }\n",
    "                    )\n",
    "            if contraction:\n",
    "                nx.contracted_nodes(\n",
    "                    G=rg,\n",
    "                    v=node,\n",
    "                    u=list(rg.successors(node))[0],\n",
    "                    self_loops=False,\n",
    "                    copy=False)\n",
    "    # parallel (Dask) processing\n",
    "    else:\n",
    "        raise NotImplementedError(\"Dask parallel scheme is not implemented yet.\")\n",
    "        \n",
    "    return predecessors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02e8dd3f-df39-4e86-bcf6-c77b3d0277d1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{72051873: [72052241, 72053437, 72053625],\n",
       " 72034810: [72034820, 72036652, 72038747, 72039447]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregate_segments(\n",
    "    rg=rg,\n",
    "    segments=[72051873, 72034810],\n",
    "    main_id='COMID',\n",
    "    ds_main_id='NextDownID',\n",
    "    attrs=[\n",
    "        'lengthkm',\n",
    "        'uparea',\n",
    "        'order',\n",
    "        'geometry'\n",
    "    ],\n",
    "    agg_funcs={\n",
    "        'lengthkm': 'sum',\n",
    "        'uparea': 'sum',\n",
    "        'order': upstream_attr,\n",
    "        'geometry': spatial_linestring_agg,\n",
    "    },\n",
    "    agg_funcs_kwargs={},\n",
    "    contraction=True,\n",
    "    dask_client=None, # serial run\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0883f75-c501-450a-87fb-c42b94c20e45",
   "metadata": {},
   "source": [
    "____\n",
    "printing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3449255-cbd6-4b0a-b51e-71f976f80e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_riv = gpd.GeoDataFrame.from_dict(rg.nodes, orient='index').drop(columns=['contraction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8053a0db-d85c-4409-8ff0-b6d38f33d535",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_riv.to_file('./temp/riv_71.shp')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scienv",
   "language": "python",
   "name": "scienv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
